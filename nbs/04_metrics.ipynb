{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "Metrics we use repeatedly to benchmark machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 10:29:27.583161: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 10:29:27.593182: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732724967.605324 1199630 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732724967.608672 1199630 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 10:29:27.619867: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/eric/miniconda3/envs/pisces/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from enum import Enum, auto\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "from pisces.deep_unet_support import *\n",
    "from typing import DefaultDict, Iterable\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from pisces.utils import determine_header_rows_and_delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WASA _p_\n",
    "\n",
    "We focus on the wake accuracy when the threshold for sleep-vs-wake binarization of class probabilities is chosen such that the sleep accuracy is _p_\\%.\n",
    "\n",
    "If we consider SLEEP to be the positive class, then the sleep accuracy is also the sensitivity, and the wake accuracy is the specificity. Thus, WASA _p_ is the specificity when the sensitivity is _p_\\%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import keras.ops as ops\n",
    "from keras.metrics import Metric, SpecificityAtSensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class WASAMetric(Metric):\n",
    "    def __init__(self, sleep_accuracy=0.95, from_logits: bool=False, **kwargs):\n",
    "        name = f\"WASA{int(100 * sleep_accuracy)}\"\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.sleep_accuracy = sleep_accuracy\n",
    "        self.from_logits = from_logits\n",
    "        self.specificity_metric = SpecificityAtSensitivity(sleep_accuracy)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert 4-class probabilities to binary probabilities\n",
    "        if sample_weight is None:\n",
    "            sample_weight = ops.ones_like(y_true)\n",
    "        \n",
    "        if self.from_logits:\n",
    "            y_pred = ops.softmax(y_pred)\n",
    "        \n",
    "        binary_probs = ops.sum(y_pred[..., 1:], axis=-1)  # Sum probabilities for classes 1, 2, 3 (sleep)\n",
    "        binary_weight = ops.where(sample_weight > 0, 1.0, 0.0)\n",
    "        binary_labels = ops.where(y_true > 0, 1.0, 0.0)  # 0 for wake, 1 for sleep\n",
    "        self.specificity_metric.update_state(binary_labels, binary_probs, binary_weight)\n",
    "    \n",
    "    def result(self):\n",
    "        return self.specificity_metric.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class PerformanceMetrics:\n",
    "    def __init__(self, sleep_accuracy, wake_accuracy, tst_error, ):\n",
    "        self.sleep_accuracy = sleep_accuracy\n",
    "        self.wake_accuracy = wake_accuracy\n",
    "        self.tst_error = tst_error\n",
    "\n",
    "\n",
    "def apply_threshold(labels, predictions, threshold):\n",
    "    true_wakes = np.where(labels == 0)[0]\n",
    "    predicted_wakes = np.where(predictions > threshold)[0]\n",
    "\n",
    "    # calculate the number of true positives\n",
    "    wake_accuracy = len(set(true_wakes).intersection(\n",
    "        set(predicted_wakes))) / len(true_wakes)\n",
    "\n",
    "    # calculate the sleep accuracy\n",
    "    true_sleeps = np.where(labels > 0)[0]\n",
    "    predicted_sleeps = np.where((predictions <= threshold) & (labels != -1))[0]\n",
    "\n",
    "    sleep_accuracy = len(set(true_sleeps).intersection(\n",
    "        set(predicted_sleeps))) / len(true_sleeps)\n",
    "\n",
    "    tst_error = (len(true_sleeps) - len(predicted_sleeps)) / 2  # Minutes\n",
    "\n",
    "\n",
    "    return PerformanceMetrics(sleep_accuracy, wake_accuracy, tst_error)\n",
    "\n",
    "\n",
    "def threshold_from_binary_search(labels, wake_probabilities,\n",
    "                                 target_sleep_accuracy) -> float:\n",
    "\n",
    "    # How close to the target wake false positive rate we need to be before stopping\n",
    "    false_positive_buffer = 0.0001\n",
    "    fraction_sleep_scored_as_sleep = -1\n",
    "    binary_search_counter = 0\n",
    "\n",
    "    max_attempts_binary_search = 50\n",
    "\n",
    "    # While we haven't found the target wake false positive rate\n",
    "    # (and haven't exceeded the number of allowable searches), keep searching:\n",
    "    while (\n",
    "        fraction_sleep_scored_as_sleep < target_sleep_accuracy - false_positive_buffer\n",
    "        or fraction_sleep_scored_as_sleep\n",
    "        >= target_sleep_accuracy + false_positive_buffer\n",
    "    ) and binary_search_counter < max_attempts_binary_search:\n",
    "        # If this is the first iteration on the binary search, initialize.\n",
    "        if binary_search_counter == 0:\n",
    "            threshold_for_sleep = 0.5\n",
    "            threshold_delta = 0.25\n",
    "        else:\n",
    "            if (\n",
    "                fraction_sleep_scored_as_sleep\n",
    "                < target_sleep_accuracy - false_positive_buffer\n",
    "            ):\n",
    "                threshold_for_sleep = threshold_for_sleep + threshold_delta\n",
    "                threshold_delta = threshold_delta / 2\n",
    "\n",
    "            if (\n",
    "                fraction_sleep_scored_as_sleep\n",
    "                >= target_sleep_accuracy + false_positive_buffer\n",
    "            ):\n",
    "                threshold_for_sleep = threshold_for_sleep - threshold_delta\n",
    "                threshold_delta = threshold_delta / 2\n",
    "\n",
    "        performance = apply_threshold(\n",
    "            labels, wake_probabilities, threshold_for_sleep)\n",
    "        fraction_sleep_scored_as_sleep = performance.sleep_accuracy\n",
    "        sens = keras.metrics.SensitivityAtSpecificity(target_sleep_accuracy)\n",
    "        one_hot_labels = keras.utils.to_categorical(labels, num_classes=2)\n",
    "        sens.update_state(one_hot_labels, wake_probabilities)\n",
    "        print(\"Sensitivity at specificity: \" + str(sens.result().numpy()))\n",
    "        print(f\"WASA{int(target_sleep_accuracy * 100)}: {performance.wake_accuracy}\")\n",
    "        print(\"Fraction sleep correct: \" + str(fraction_sleep_scored_as_sleep))\n",
    "        print(\"Goal fraction sleep correct: \" + str(target_sleep_accuracy))\n",
    "        binary_search_counter = binary_search_counter + 1\n",
    "\n",
    "    print(\"Declaring victory with \" +\n",
    "          str(fraction_sleep_scored_as_sleep) + \"\\n\\n\")\n",
    "\n",
    "    print(\"Goal was: \" + str(target_sleep_accuracy))\n",
    "    return threshold_for_sleep\n",
    "\n",
    "def wasa_metric(labels, predictions, weights, target_sleep_accuracy=0.95) -> Tuple[PerformanceMetrics, float]:\n",
    "    labels = labels[weights > 0]\n",
    "    predictions = predictions[weights > 0]\n",
    "\n",
    "    labels[labels > 1] = 1\n",
    "\n",
    "    threshold = threshold_from_binary_search(labels, predictions, target_sleep_accuracy)\n",
    "\n",
    "    perform = apply_threshold(\n",
    "        labels, predictions, threshold)\n",
    "\n",
    "    return perform, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
