{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> Module of utility functions used throughout the package, for things like common preprocessing steps many models are likely to use, or useful for multiple points of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from enum import Enum, auto\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def determine_header_rows_and_delimiter(\n",
    "    filename: Path | str\n",
    ") -> Tuple[Optional[int], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Given a filename pointing at a CSV files, decides:\n",
    "     * how many header lines there are (based on first line starting with a digit)\n",
    "     * the delimiter-- right now tries whitespace and comma\n",
    "\n",
    "    Returns one of:\n",
    "     - (number of header rows, column delimiter),\n",
    "     - (number of header rows, None) if the delimiter could not be inferred,\n",
    "     - (None, None) if CSV has no numerical rows,\n",
    "\n",
    "    :param filename: CSV Path or filepath literal\n",
    "    :return: header and delimiter information, if possible.\n",
    "    \"\"\"\n",
    "    MAX_ROWS = 100  # if you don't have data within first 100 lines, exit.\n",
    "    header_row_count = 0\n",
    "    with open(filename) as f:\n",
    "        header_found = False\n",
    "        line = \"\"  # modified in while below\n",
    "\n",
    "        # Search over lines until we find one starting with a digit\n",
    "        while not header_found:\n",
    "            line = f.readline()\n",
    "            if line == \"\":  # last line of file reached\n",
    "                return None, None\n",
    "            line = line.strip()\n",
    "            try:\n",
    "                int(line[0])\n",
    "                header_found = True\n",
    "            except ValueError:\n",
    "                header_row_count += 1\n",
    "            except IndexError:\n",
    "                header_row_count += 1\n",
    "\n",
    "            # guard against infinite loop\n",
    "            if header_row_count >= MAX_ROWS:\n",
    "                return None, None\n",
    "\n",
    "        # Now try splitting that first line of data\n",
    "        delim_guesses = [\" \", \",\", \", \"]\n",
    "\n",
    "        for guess in delim_guesses:\n",
    "            try:\n",
    "                comps = line.split(guess)  # whitespace separated?\n",
    "                float(comps[0])\n",
    "                return header_row_count, guess\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return header_row_count, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ActivityCountAlgorithm(Enum):\n",
    "    te_Lindert_et_al = 0\n",
    "    ActiGraphOfficial = 1\n",
    "    ADS = 2\n",
    "\n",
    "\n",
    "def build_activity_counts(\n",
    "    data,\n",
    "    axis: int = 3,\n",
    "    prefix: str = \"\",\n",
    "    algorithm: ActivityCountAlgorithm = ActivityCountAlgorithm.ADS\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    if algorithm == ActivityCountAlgorithm.ActiGraphOfficial:\n",
    "        return build_ActiGraph_official(data)\n",
    "    if algorithm == ActivityCountAlgorithm.ADS:\n",
    "        return build_ADS(data)\n",
    "    if algorithm == ActivityCountAlgorithm.te_Lindert_et_al:\n",
    "        return build_activity_counts_te_Lindert_et_al(data, axis, prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    [1, 1, 1],\n",
    "    [3, 4, 5],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.73205081, 7.07106781])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.16227766, 4.12310563, 5.09901951])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def build_ADS(\n",
    "    time_xyz: np.ndarray,\n",
    "    sampling_hz: float = 50.0,\n",
    "    bin_size_seconds: float = 15,\n",
    "    prefix: str = \"\",\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"ADS algorithm for activity counts, developed by Arcascope with support from the NHRC.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "     - `time_xyz`: numpy array with shape (N_samples, 4) where the 4 coordinates are: [time, x, y, z] \n",
    "     - `sampling_hz`: `float` sampling frequency of thetime_xyz \n",
    "    \"\"\"\n",
    "    data_shape_error = ValueError(\n",
    "            f\"`time_xyz` must have shape (N_samples, 4) but has shape {time_xyz.shape}\"\n",
    "        )\n",
    "    try:\n",
    "        assert (len(time_xyz.shape) == 2 and time_xyz.shape[1] == 4)\n",
    "    except AssertionError:\n",
    "        raise data_shape_error\n",
    "\n",
    "    time_data_raw = time_xyz[:, 0]\n",
    "    x_accel = time_xyz[:, 1]\n",
    "    y_accel = time_xyz[:, 2]\n",
    "    z_accel = time_xyz[:, 3]\n",
    "\n",
    "    # Interpolate to sampling Hz\n",
    "    time_values = np.arange(\n",
    "        np.amin(time_data_raw), np.amax(time_data_raw), 1 / sampling_hz\n",
    "    )\n",
    "    # Must do each coordinate separately\n",
    "    x_data = np.interp(time_values, time_data_raw, x_accel)\n",
    "    y_data = np.interp(time_values, time_data_raw, y_accel)\n",
    "    z_data = np.interp(time_values, time_data_raw, z_accel)\n",
    "\n",
    "    # Calculate \"amplitude\" = timeseries of 2-norm of (x, y, z)\n",
    "    amplitude = np.linalg.norm(np.array([x_data, y_data, z_data]), axis = 0)\n",
    "\n",
    "    abs_amplitude_deriv = np.abs(np.diff(amplitude))\n",
    "    abs_amplitude_deriv = np.insert(abs_amplitude_deriv, 0, 0)\n",
    "\n",
    "    # Binning step\n",
    "    # Sum abs_amplitude_deriv in time-based windows\n",
    "    # ex: bin_size_seconds = 15\n",
    "    # Step from first to last time by 15 seconds\n",
    "    time_counts = np.arange(\n",
    "        np.amin(time_data_raw), np.amax(time_data_raw), bin_size_seconds\n",
    "    )\n",
    "\n",
    "    # Convert time at 50 hz to \"# of 15 second windows past start\"\n",
    "    bin_values = (time_values - time_values[0]).astype(int) // bin_size_seconds\n",
    "    sums_in_bins = np.bincount(bin_values, abs_amplitude_deriv)\n",
    "    sums_in_bins[sums_in_bins <= 0.05 * max(sums_in_bins)] = 0.0\n",
    "    return time_counts, sums_in_bins\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def build_activity_counts_te_Lindert_et_al(\n",
    "    time_xyz, axis: int = 3, prefix: str = \"\"\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Implementation of the reverse-engineered activity count algorithm from\n",
    "    te Lindert BH, Van Someren EJ. Sleep. 2013\n",
    "    Sleep estimates using microelectromechanical systems (MEMS). \n",
    "    doi: 10.5665/sleep.2648\n",
    "    \n",
    "    :param time_xyz: `np.ndarray` loaded from timestamped triaxial accelerometer CSV. Shape (N, 4)\n",
    "    :return: (time, activity counts with 15 second epoch)\n",
    "    \"\"\"\n",
    "\n",
    "    # a helper function to calculate max over 2 epochs\n",
    "    def max2epochs(data, fs, epoch):\n",
    "        data = data.flatten()\n",
    "\n",
    "        seconds = int(np.floor(np.shape(data)[0] / fs))\n",
    "        data = np.abs(data)\n",
    "        data = data[0 : int(seconds * fs)]\n",
    "\n",
    "        data = data.reshape(fs, seconds, order=\"F\").copy()\n",
    "\n",
    "        data = data.max(0)\n",
    "        data = data.flatten()\n",
    "        N = np.shape(data)[0]\n",
    "        num_epochs = int(np.floor(N / epoch))\n",
    "        data = data[0 : (num_epochs * epoch)]\n",
    "\n",
    "        data = data.reshape(epoch, num_epochs, order=\"F\").copy()\n",
    "        epoch_data = np.sum(data, axis=0)\n",
    "        epoch_data = epoch_data.flatten()\n",
    "\n",
    "        return epoch_data\n",
    "    \n",
    "    fs = 50\n",
    "    time = np.arange(np.amin(time_xyz[:, 0]), np.amax(time_xyz[:, 0]), 1.0 / fs)\n",
    "    z_data = np.interp(time, time_xyz[:, 0], time_xyz[:, axis])\n",
    "\n",
    "    cf_low = 3\n",
    "    cf_hi = 11\n",
    "    order = 5\n",
    "    w1 = cf_low / (fs / 2)\n",
    "    w2 = cf_hi / (fs / 2)\n",
    "    pass_band = [w1, w2]\n",
    "    b, a = butter(order, pass_band, \"bandpass\")\n",
    "\n",
    "    z_filt = filtfilt(b, a, z_data)\n",
    "    z_filt = np.abs(z_filt)\n",
    "\n",
    "    top_edge = 5\n",
    "    bottom_edge = 0\n",
    "    number_of_bins = 128\n",
    "\n",
    "    bin_edges = np.linspace(bottom_edge, top_edge, number_of_bins + 1)\n",
    "    binned = np.digitize(z_filt, bin_edges)\n",
    "    epoch = 15\n",
    "    counts = max2epochs(binned, fs, epoch)\n",
    "    counts = (counts - 18) * 3.07\n",
    "    counts[counts < 0] = 0\n",
    "\n",
    "    time_counts = np.linspace(np.min(time_xyz[:, 0]), max(time_xyz[:, 0]), np.shape(counts)[0])\n",
    "    time_counts = np.expand_dims(time_counts, axis=1)\n",
    "    counts = np.expand_dims(counts, axis=1)\n",
    "\n",
    "    return time_counts, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from agcounts.extract import get_counts\n",
    "\n",
    "def build_ActiGraph_official(time_xyz, axis: int = 3) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    freq = 50\n",
    "    counts = get_counts(time_xyz[:, 1:], freq=freq, epoch=15)[:, axis - 1]\n",
    "    times = np.linspace(time_xyz[0, 0], time_xyz[-1, 0], len(counts))\n",
    "\n",
    "    return times, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pisces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
