{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enums\n",
    "\n",
    "> Module containing enums refererenced throughout the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp enums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from enum import Enum, auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SleepOrWake(Enum):\n",
    "    \"\"\"\n",
    "    Very simple enum for fixing, once-and-for-all, meaning of class 0 and 1.\n",
    "    Use this enum when sensible for clarity in code.\n",
    "    \"\"\"\n",
    "\n",
    "    DO_NOT_USE = -2  # excluded post-hoc, e.g. padding\n",
    "    UNSCORED = -1\n",
    "    WAKE = 0\n",
    "    SLEEP = 1\n",
    "\n",
    "    \n",
    "class SleepStagesWLDR(Enum):\n",
    "    \"\"\"\n",
    "    Similar to SleepStages(Enum), but for Wake/Light/Deep/REM instead of Ns\n",
    "    \"\"\"\n",
    "\n",
    "    DO_NOT_USE = -2  # excluded post-hoc, e.g. padding\n",
    "    UNSCORED = -1\n",
    "    WAKE = 0\n",
    "    LIGHT = 1\n",
    "    DEEP = 2\n",
    "    REM = 3\n",
    "\n",
    "    def to_masked_sleep_wake(self) -> SleepOrWake:\n",
    "        match self:\n",
    "            case SleepStagesWLDR.DO_NOT_USE:\n",
    "                return SleepOrWake.DO_NOT_USE\n",
    "            case SleepStagesWLDR.UNSCORED:\n",
    "                return SleepOrWake.UNSCORED\n",
    "            case SleepStagesWLDR.WAKE:\n",
    "                return SleepOrWake.WAKE\n",
    "            case _:\n",
    "                return SleepOrWake.SLEEP\n",
    "    \n",
    "class SleepStages(Enum):\n",
    "    \"\"\"\n",
    "    Very simple enum for fixing, once-and-for-all, meaning of integer sleep stages.\n",
    "    Use this enum when possible for clarity in code.\n",
    "    \"\"\"\n",
    "\n",
    "    DO_NOT_USE = -2  # excluded post-hoc, e.g. padding\n",
    "    UNSCORED = -1\n",
    "    WAKE = 0\n",
    "    N1 = 1\n",
    "    N2 = 2\n",
    "    N3 = 3\n",
    "    N4 = 4\n",
    "    REM = 5\n",
    "\n",
    "    def to_masked_sleep_wake(self) -> SleepOrWake:\n",
    "        return self.to_WLDR().to_masked_sleep_wake()\n",
    "\n",
    "    def to_WLDR(self) -> SleepStagesWLDR:\n",
    "        match self:\n",
    "            case SleepStages.DO_NOT_USE:\n",
    "                return SleepOrWake.DO_NOT_USE\n",
    "            case SleepStages.UNSCORED:\n",
    "                return SleepStagesWLDR.UNSCORED\n",
    "            case SleepStages.WAKE:\n",
    "                return SleepStagesWLDR.WAKE\n",
    "            case SleepStages.N1 | SleepStages.N2:\n",
    "                return SleepStagesWLDR.LIGHT\n",
    "            case SleepStages.N3 | SleepStages.N4:\n",
    "                return SleepStagesWLDR.DEEP\n",
    "            case SleepStages.REM:\n",
    "                return SleepStagesWLDR.REM\n",
    "\n",
    "\n",
    "PSG_Enums = SleepOrWake | SleepStagesWLDR | SleepStages\n",
    "\n",
    "\n",
    "class SleepClassificationProblem(Enum):\n",
    "    SLEEP_OR_WAKE = auto()\n",
    "    SLEEP_STAGES_WLDR = auto()\n",
    "    SLEEP_STAGES = auto()\n",
    "\n",
    "    def type_enum(self) -> PSG_Enums:\n",
    "        match self:\n",
    "            case SleepClassificationProblem.SLEEP_OR_WAKE:\n",
    "                return SleepOrWake\n",
    "            case SleepClassificationProblem.SLEEP_STAGES_WLDR:\n",
    "                return SleepStagesWLDR\n",
    "            case SleepClassificationProblem.SLEEP_STAGES:\n",
    "                return SleepStages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class KnownFeatures(Enum):\n",
    "    \"\"\"\n",
    "    Expresses to the system which features from data to include.\n",
    "    This lives here for cyclic import reasons...\n",
    "    \"\"\"\n",
    "\n",
    "    ACTIVITY = auto()\n",
    "    ACCELEROMETER = auto()\n",
    "    HEARTRATE = auto()\n",
    "    PSG = auto()\n",
    "\n",
    "    # Not settable, derived\n",
    "    ACCEL_SPECTRO = auto()\n",
    "    MO_SPECTRO = auto()  # Mads Olsen preprocessing\n",
    "\n",
    "    @property\n",
    "    def base_feature(self) -> \"KnownFeatures\":\n",
    "        if self.is_accelerometer_based:\n",
    "            return KnownFeatures.ACCELEROMETER\n",
    "        elif self.is_activity_based:\n",
    "            return KnownFeatures.ACTIVITY\n",
    "        elif self.is_heartrate_based:\n",
    "            return KnownFeatures.HEARTRATE\n",
    "        else:\n",
    "            return self\n",
    "\n",
    "    @property\n",
    "    def is_derived(self) -> bool:\n",
    "        match self:\n",
    "            case KnownFeatures.ACTIVITY | KnownFeatures.ACCELEROMETER | KnownFeatures.HEARTRATE | KnownFeatures.PSG:\n",
    "                return False\n",
    "            case _:\n",
    "                return True\n",
    "\n",
    "    @property\n",
    "    def is_spectral(self) -> bool:\n",
    "        return self in [KnownFeatures.ACCEL_SPECTRO, KnownFeatures.MO_SPECTRO]\n",
    "\n",
    "    @property\n",
    "    def is_accelerometer_based(self) -> bool:\n",
    "        # Convenience + readability helper\n",
    "        return self in [\n",
    "            KnownFeatures.ACCELEROMETER,\n",
    "            KnownFeatures.ACCEL_SPECTRO,\n",
    "            KnownFeatures.MO_SPECTRO,\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def is_activity_based(self) -> bool:\n",
    "        return self in [KnownFeatures.ACTIVITY]\n",
    "\n",
    "    @property\n",
    "    def is_heartrate_based(self) -> bool:\n",
    "        return self in [KnownFeatures.HEARTRATE]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class KnownModel(Enum):\n",
    "    \"\"\"\n",
    "    Enumerates known ML models. Allows for programmatic selection via JSON, produces Python classes as neeeded.\n",
    "\n",
    "    For example, KnownModel['COLE_KRIPKE'] will produce the KnownModel.COLE_KRIPKE enum value. This allows us to \n",
    "    \"COLE_KRIPKE\" as a model to use in a JSON file, and then turn that into an enum which we can switch on in a \n",
    "    factory to make the actual, trainable models. TODO?: Mixin the trainable model class, so the enum can be trained?\n",
    "    \"\"\"\n",
    "\n",
    "    COLE_KRIPKE = auto()\n",
    "    LOG_REG_SKLEARN = auto()\n",
    "    # LOG_REG_CONV = auto()\n",
    "    # SVM = auto()\n",
    "    # XGBOOST = auto()\n",
    "    # UPDOWN = auto()  # UpDownTimeSeriesClassifier\n",
    "    # CONV_SPECTRO = auto()\n",
    "    # SPECTRO_AUTOENCODER = auto()\n",
    "    # LREP_LOG_REG = auto()  # LatentRepresentationLogRegClassifier\n",
    "    # LREP_XGB = auto()  # Latent Representation with XGBoosted tree latent rep classifier\n",
    "    # TRIAX_AUTOENC = auto()\n",
    "    # ### Mads Olsen et al 2022 networks below\n",
    "    # # PyTorch translation\n",
    "    # MO_UNET = auto()\n",
    "    # # Trainable TensorFlow model. Code copy-pasted from MO, wrapped into SleepWakeClassifier\n",
    "    # MO_UNET_TF = auto()\n",
    "    # # Pretrained weights from Mads Olsen's GitHub. Tensforflow lite.\n",
    "    # PRETRAINED_MO_UNET = auto()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import List, Optional\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "class ValidationMethod(Enum):\n",
    "    \"\"\"\n",
    "    Describes to a pipeline how it should iterate over the data provided, splitting into training and testing sets.\n",
    "    We want to avoid splitting a subject's data across train and test folds! This leaks too much info to the classifiers\n",
    "    \"\"\"\n",
    "\n",
    "    LOOX = -1\n",
    "    LEAVE_ONE_OUT = 0\n",
    "\n",
    "    def make_splits(\n",
    "        self, param: Optional[float | int | str], data_record_set_names: List[str]\n",
    "    ) -> List[List[List[int]]]:\n",
    "        \"\"\"\n",
    "        Using the validation method represented by self, produce list-of-lists of train/test splits by\n",
    "        :param param: Parameter used in the method.\n",
    "         - For LEAVE_ONE_OUT this is ignored.\n",
    "         - For K_FOLD this is K\n",
    "         - For RANDOM_PERCENTILE this is the training fraction\n",
    "        :param samples: List of identifiers of the data records being split. An id can be anything, up to you.\n",
    "        :return: List of lists of length 2: [..., [[split j training indices], [split j testing indices]], ...]\n",
    "        \"\"\"\n",
    "        if self == ValidationMethod.LOOX:\n",
    "            \"\"\"==================================================\n",
    "            START: Confusing boilderplate to parse the train and test set\n",
    "            ==================================================\"\"\"\n",
    "            try:\n",
    "                train_set, test_set = param.split(\",\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\n",
    "                    'Specify \"<train set name>,<test set name>\" as \"param\" value in validation config.'\n",
    "                )\n",
    "                print(\n",
    "                    'or \"train:<train set name>,test:<test set name>\" with \"train:\" and \"test\" in either order, depending on your preference.'\n",
    "                )\n",
    "            if \":\" in train_set or \":\" in test_set:\n",
    "                *tr_or_tst, first_set = train_set.split(\":\")\n",
    "                *tst_or_tr, second_set = test_set.split(\":\")\n",
    "\n",
    "                # One of these branches should catch based on enclosing `if`\n",
    "                if tr_or_tst:\n",
    "                    if tr_or_tst[0] == \"train\":\n",
    "                        train_set = first_set\n",
    "                        test_set = second_set\n",
    "                    elif tr_or_tst[0] == \"test\":\n",
    "                        train_set = second_set\n",
    "                        test_set = first_set\n",
    "                elif tst_or_tr:\n",
    "                    if tst_or_tr[0] == \"test\":\n",
    "                        train_set = first_set\n",
    "                        test_set = second_set\n",
    "                    elif tst_or_tr[0] == \"train\":\n",
    "                        train_set = second_set\n",
    "                        test_set = first_set\n",
    "\n",
    "            \"\"\"==================================================\n",
    "            END: Confusing boilderplate to parse the train and test set\n",
    "            ==================================================\"\"\"\n",
    "\n",
    "            print(\n",
    "                f\"training LOOX: Leave-one-out, swapping left-out {train_set} for {test_set}\"\n",
    "            )\n",
    "\n",
    "            tests = [\n",
    "                j for j in range(len(data_record_set_names)) if data_record_set_names[j] == test_set\n",
    "            ]\n",
    "            trains = [\n",
    "                j for j in range(len(data_record_set_names)) if data_record_set_names[j] == train_set\n",
    "            ]\n",
    "            splits = [\n",
    "                [skipping_index(trains, index=j), [tests[j]]] for j in range(len(tests))\n",
    "            ]\n",
    "\n",
    "            return splits\n",
    "\n",
    "        if self == ValidationMethod.LEAVE_ONE_OUT:\n",
    "            return LeaveOneOut().split(X=range(len(data_record_set_names)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pisces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
