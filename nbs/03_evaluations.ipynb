{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluations\n",
    "\n",
    "> This module defines the outputs of the experiments you can run with pisces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "from enum import Enum, auto\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test split evaluation\n",
    "\n",
    "The fundamental organization of a `pisces` pipeline run is the train-test split. Because we tend to care about inference capabilities on unseen data, it's natural to think about the splits being parametrized by the testing set; often one uses LOO validation methods on patient data, so it links up naturally with thinking of the performance of a trained model _on this patient/subject._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ValidationMethod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| export\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpisces\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StudyRecord\n",
      "File \u001b[0;32m~/Engineering/Work/pisces/pisces/loader.py:12\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mValidationConfiguration\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     parameter: Optional[\u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m     14\u001b[0m     method: ValidationMethod\n",
      "File \u001b[0;32m~/Engineering/Work/pisces/pisces/loader.py:14\u001b[0m, in \u001b[0;36mValidationConfiguration\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mValidationConfiguration\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     parameter: Optional[\u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m     method: \u001b[43mValidationMethod\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameter: Optional[\u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m], method: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter \u001b[38;5;241m=\u001b[39m parameter\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ValidationMethod' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from pisces.loader import StudyRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy.typing as npt\n",
    "\n",
    "from pisces.records import TimeseriesRecording\n",
    "\n",
    "\n",
    "class PSGPredictionsShapeError(Exception):\n",
    "    \"\"\"\n",
    "    An exception to be raised when the shape of the predictions is invalid.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args: object) -> None:\n",
    "        super().__init__(*args)\n",
    "\n",
    "\n",
    "class PSGPredictionsNotProbabilityVectorError(Exception):\n",
    "    \"\"\"\n",
    "    An exception to be raised when the predictions are not a probability vector.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args: object) -> None:\n",
    "        super().__init__(*args)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PSGModelOutputs(TimeseriesRecording):\n",
    "    \"\"\"\n",
    "    TimeseriesRecording output from models; models should type a specific subclass of\n",
    "    this in the return type of their evaluate method.\n",
    "\n",
    "    Probabilities should be a NumPy array shaped such that\n",
    "        self.probabilities[i]\n",
    "    indicates the probabilities of each sleep stage for times between\n",
    "        self.time[i] and self.time[i+1]\n",
    "    In particular, self.probabilities should have shape\n",
    "        (N,) or (N, m)\n",
    "    where N == len(self.time) and m = number of stages\n",
    "    \"\"\"\n",
    "\n",
    "    probabilities: npt.NDArray[np.float64]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"This is a special dunder method for dataclasses that is called after __init__. You can override this in your subclass to do any additional validation; call super().__post_init__() within your override to run this class's method as part of it.\"\"\"\n",
    "        if len(self.time) != len(self.probabilities):\n",
    "            raise PSGPredictionsShapeError(f\"{len(self.probabilities)} == len(probabilities) must equal len(time) == {len(self.time)}\")\n",
    "\n",
    "        if not np.all(self.probabilities <= 1.0):\n",
    "            raise PSGPredictionsNotProbabilityVectorError(\n",
    "                \"Probabilities vector must contain entries between 0.0 and 1.0, inclusive.\"\n",
    "            )\n",
    "\n",
    "        if self.probabilities.shape not in self.valid_probability_shapes(self.time):\n",
    "            raise PSGPredictionsShapeError(\"Probabilities vector has invalid shape, must be one of: \" + str(self.valid_probability_shapes()))\n",
    "    \n",
    "    def valid_probability_shapes(self) -> List[Tuple[int, ...]]:\n",
    "        \"\"\"\n",
    "        Returns a list of valid shapes for the probabilities array\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _sort_specific_data(self, sort_idx: npt.NDArray[np.int64]) -> None:\n",
    "        self.probabilities = self.probabilities[sort_idx]\n",
    "\n",
    "    def _trim_specific_data(self, select_idx: np.ndarray) -> None:\n",
    "        if select_idx.dtype == bool:\n",
    "            # Reduce to case where indices to include are provided\n",
    "            select_idx = np.nonzero(select_idx)\n",
    "        self.probabilities = self.probabilities[select_idx]\n",
    "\n",
    "\n",
    "class PSGSleepWakePredictions(PSGModelOutputs):\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "    \n",
    "    def valid_probability_shapes(self) -> List[Tuple[int, ...]]:\n",
    "        return [(len(self.time),), (len(self.time), 1), (len(self.time), 2)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSplit:\n",
    "    def __init__(self, test_split: List[StudyRecord]):\n",
    "        self.test_split = test_split\n",
    "\n",
    "\n",
    "class TestSplitEvaluation:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
