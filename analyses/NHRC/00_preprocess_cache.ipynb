{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "import pisces.models as pm\n",
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from pisces.data_sets import DataSetObject, ModelInputSpectrogram, ModelOutputType, DataProcessor, PSGType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths for caching\n",
    "Set up all the paths here, ensure the (sub)folders all exist so later when we try to save to these there are no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "CWD = Path(os.getcwd())\n",
    "save_path = CWD.joinpath(\"pre_processed_data\")\n",
    "hybrid_path = save_path.joinpath(\"hybrid\")\n",
    "os.makedirs(hybrid_path, exist_ok=True)\n",
    "disordered_path = save_path.joinpath(\"disordered\")\n",
    "os.makedirs(disordered_path, exist_ok=True)\n",
    "walch_path = save_path.joinpath(\"walch\")\n",
    "os.makedirs(walch_path, exist_ok=True)\n",
    "data_location = Path('/Users/eric/Engineering/Work/pisces/data_sets')#CWD.parent.joinpath(\"data_sets\")\n",
    "# data_location = Path('/home/eric/Engineering/Work/pisces/data_sets')#CWD.parent.joinpath(\"data_sets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/eric/Engineering/Work/pisces/data_sets')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Mads Olsen model to Keras...\n",
      "Model saved at /Users/eric/Engineering/Work/pisces/pisces/cached_models/mo_resunet.keras\n"
     ]
    }
   ],
   "source": [
    "!pisces_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 subjects\n",
      "Found 31 subjects\n"
     ]
    }
   ],
   "source": [
    "sets = DataSetObject.find_data_sets(data_location)\n",
    "walch = sets['walch_et_al']\n",
    "walch.parse_data_sets()\n",
    "print(f\"Found {len(walch.ids)} subjects\")\n",
    "\n",
    "hybrid = sets['hybrid_motion']\n",
    "hybrid.parse_data_sets()\n",
    "print(f\"Found {len(hybrid.ids)} subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_to_exclude_walch = [\n",
    "    \"3509524\", \"5383425\",\n",
    "    \"7749105\",\"759667\",\n",
    "    \"8258170\",\n",
    "    \"9961348\", \"5132496\",\n",
    "]\n",
    "\n",
    "# SAME subjects, hybrid is fuzzed data\n",
    "subjects_to_exclude_hybrid = subjects_to_exclude_walch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_hz = 32 # Hz\n",
    "input_features = ['accelerometer']\n",
    "model_input = ModelInputSpectrogram(input_features, sampling_hz)\n",
    "output_type = ModelOutputType.WAKE_LIGHT_DEEP_REM\n",
    "data_processor_walch = DataProcessor(walch, model_input, output_type=output_type,\n",
    "                                     psg_type=PSGType.HAS_N4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = pm.MOResUNetPretrained(data_processor=data_processor_walch, sampling_hz=sampling_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "import pisces.data_sets as pds\n",
    "\n",
    "FIXED_LABEL_LENGTH = 1024\n",
    "# FIXED_SPECGRAM_SHAPE = (15360, 32, 3)\n",
    "FIXED_SPECGRAM_SHAPE = (15360, 32)\n",
    "\n",
    "ACC_RAW_HZ = 50\n",
    "ACC_RAW_DT = 1/ACC_RAW_HZ\n",
    "ACC_INPUT_HZ = 32\n",
    "ACTIVITY_RATE = 15\n",
    "ACTIVITY_HZ = 1/ACTIVITY_RATE\n",
    "PSG_RATE = 30\n",
    "PSG_HZ = 1/PSG_RATE\n",
    "SECONDS_PER_KERNEL = 5 * 60\n",
    "ACTIVITY_KERNEL_WIDTH = SECONDS_PER_KERNEL * ACTIVITY_HZ\n",
    "ACTIVITY_KERNEL_WIDTH += 1 - (ACTIVITY_KERNEL_WIDTH % 2)  # Ensure it is odd\n",
    "\n",
    "def process_data(dataset: pds.DataSetObject, id, ACTIVITY_KERNEL_WIDTH):\n",
    "    # Load data\n",
    "    accel_data = dataset.get_feature_data('accelerometer', id).to_numpy()\n",
    "    activity_data = dataset.get_feature_data('activity', id).to_numpy()\n",
    "    psg_data = dataset.get_feature_data('psg', id).to_numpy()\n",
    "\n",
    "    # Sort based on time (axis 0)\n",
    "    accel_data = accel_data[accel_data[:, 0].argsort()]\n",
    "    activity_data = activity_data[activity_data[:, 0].argsort()]\n",
    "    psg_data = psg_data[psg_data[:, 0].argsort()]\n",
    "\n",
    "    # Convert activity and PSG time to int\n",
    "    activity_data[:, 0] = np.round(activity_data[:, 0])\n",
    "    psg_data[:, 0] = np.round(psg_data[:, 0])\n",
    "    \n",
    "    # Trim data to common time range\n",
    "    start_time = max(accel_data[0, 0], activity_data[0, 0], psg_data[0, 0])\n",
    "    end_time = min(accel_data[-1, 0], activity_data[-1, 0], psg_data[-1, 0])\n",
    "    \n",
    "    accel_data = accel_data[(accel_data[:, 0] >= start_time) & (accel_data[:, 0] <= end_time)]\n",
    "    activity_data = activity_data[(activity_data[:, 0] >= start_time) & (activity_data[:, 0] <= end_time)]\n",
    "    psg_data = psg_data[(psg_data[:, 0] >= start_time) & (psg_data[:, 0] <= end_time)]\n",
    "\n",
    "    # print(\"PSG Shape\", psg_data.shape)\n",
    "    \n",
    "    # Find gaps in accelerometer data\n",
    "    time_diff = np.diff(accel_data[:, 0])\n",
    "    avg_time_hz = int(1/np.median(time_diff))\n",
    "    avg_time_diff = 1/avg_time_hz\n",
    "    threshold = 100 * avg_time_diff\n",
    "    gap_indices = np.where(time_diff > threshold)[0]\n",
    "    # print(\"avg_time_diff\", avg_time_diff)\n",
    "    # print(\"threshold\", threshold)\n",
    "    # print(f\"Found {len(gap_indices)} gaps in accelerometer data\")\n",
    "    \n",
    "    # Mask PSG labels during accelerometer gaps\n",
    "    n_psg_mask = np.sum(psg_data[:, 1] < 0)\n",
    "    len_psg = psg_data.shape[0]\n",
    "    # print(\"# of masked epochs: \", n_psg_mask, \"out of\", len_psg, f\"({100 * n_psg_mask / len_psg:.2f}%)\")\n",
    "    pre_mask_sleeps = np.sum(psg_data[:, 1] > 0)\n",
    "    pre_mask_wakes = np.sum(psg_data[:, 1] == 0)\n",
    "    wakes_masked = 0\n",
    "    print(\"Pre-mask:\\n\\tSleeps\", pre_mask_sleeps, \"\\n\\tWakes\", pre_mask_wakes)\n",
    "    for gap_index in gap_indices:\n",
    "        gap_start = accel_data[gap_index, 0] + avg_time_diff\n",
    "        gap_end = accel_data[gap_index + 1, 0]\n",
    "        mask_indices = np.where((psg_data[:, 0] + PSG_RATE >= gap_start) & (psg_data[:, 0] <= gap_end))[0]\n",
    "        wake_counts = np.sum((psg_data[mask_indices, 1].astype(int)) == 0)\n",
    "        wakes_masked += wake_counts\n",
    "        sleep_counts = np.sum((psg_data[mask_indices, 1].astype(int)) > 0)\n",
    "        # print(f\"Gap {gap_index}:\\n\\twakes masked: {wake_counts}\\n\\tsleeps masked: {sleep_counts}\")\n",
    "        psg_data[mask_indices, 1:] = -1  # Assuming labels are in columns from index 1 onwards\n",
    "    # print(\"END gap masking: # of masked epochs: \", np.sum(psg_data[:, 1] < 0), \"out of\", len_psg)\n",
    "    \n",
    "    # Mask PSG labels at start and end based on ACTIVITY_KERNEL_WIDTH\n",
    "    labels_per_activity = PSG_RATE * ACTIVITY_HZ\n",
    "    num_labels_to_mask = int(np.ceil((ACTIVITY_KERNEL_WIDTH // 2) // labels_per_activity))\n",
    "    if num_labels_to_mask > 0:\n",
    "        # print(f\"MASKING {num_labels_to_mask} LABELS from either end\")\n",
    "        psg_data[:num_labels_to_mask, 1:] = -1\n",
    "        psg_data[-num_labels_to_mask:, 1:] = -1\n",
    "    post_mask_sleeps = np.sum(psg_data[:, 1] > 0)\n",
    "    post_mask_wakes = np.sum(psg_data[:, 1] == 0)\n",
    "    print(\"Post-mask:\\n\\tSleeps\", post_mask_sleeps, \"\\n\\tWakes\", post_mask_wakes, \"\\n\\tWakes masked\", wakes_masked)\n",
    "    \n",
    "    # Convert accelerometer data to spectrograms\n",
    "    accel_data_resampled = resample_accel_data(accel_data, original_fs=int(avg_time_hz), target_fs=ACC_INPUT_HZ)\n",
    "    spectrograms = data_processor_walch.accelerometer_to_spectrogram(accel_data_resampled)\n",
    "    # spectrograms = data_processor_walch.accelerometer_to_spectrogram(accel_data)\n",
    "    # spectrograms = convert_accel_to_spectrogram(accel_data_resampled)\n",
    "    padded_spectrograms = np.zeros(FIXED_SPECGRAM_SHAPE)\n",
    "    padded_spectrograms[:spectrograms.shape[0], ...] = spectrograms[:FIXED_SPECGRAM_SHAPE[0], ...]\n",
    "    \n",
    "    # Pad PSG data to 1024 samples\n",
    "    psg_data = pad_or_truncate(psg_data, 1024)\n",
    "    \n",
    "    # Pad activity data to 2 * 1024 samples\n",
    "    activity_data = pad_or_truncate(activity_data, int(labels_per_activity * FIXED_LABEL_LENGTH))\n",
    "    \n",
    "    return {\"spectrogram\": padded_spectrograms, \"activity\": activity_data, \"psg\": psg_data}\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import resample_poly\n",
    "\n",
    "def resample_accel_data(accel_data, original_fs, target_fs=ACC_INPUT_HZ):\n",
    "    # Calculate the greatest common divisor for up/down sampling rates\n",
    "    up = target_fs\n",
    "    down = original_fs\n",
    "    gcd = np.gcd(int(up), int(down))\n",
    "    up = int(up // gcd)\n",
    "    down = int(down // gcd)\n",
    "\n",
    "    accel_resampled_time = np.arange(accel_data[0, 0], accel_data[-1, 0], 1/original_fs)\n",
    "\n",
    "    accel_resampled = np.zeros((len(accel_resampled_time), accel_data.shape[1]))\n",
    "    accel_resampled[:, 0] = accel_resampled_time\n",
    "\n",
    "    for i in range(1, accel_data.shape[1]):\n",
    "        accel_resampled[:, i] = np.interp(accel_resampled_time, accel_data[:, 0], accel_data[:, i])\n",
    "    \n",
    "    # Resample data (excluding the time column)\n",
    "    resampled_data = resample_poly(accel_resampled[:, 1:], up, down, axis=0)\n",
    "    \n",
    "    # Recompute the time vector\n",
    "    duration = accel_data[-1, 0] - accel_data[0, 0]\n",
    "    num_samples = resampled_data.shape[0]\n",
    "    new_time = np.linspace(accel_resampled_time[0], accel_resampled_time[-1], num_samples)\n",
    "    \n",
    "    # Combine the new time vector with the resampled data\n",
    "    resampled_accel_data = np.column_stack((new_time, resampled_data))\n",
    "    return resampled_accel_data\n",
    "\n",
    "def cal_psd(x, fs=ACC_INPUT_HZ, window=320, noverlap=256, nfft=512, f_min=0, f_max=6, f_sub=3):\n",
    "    \"\"\"\n",
    "    https://github.com/MADSOLSEN/SleepStagePrediction/blob/d47ff488f5cedd3b0459593a53fc4f92fc3660a2/signal_processing/spectrogram.py#L91\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import maximum_filter as maxfilt\n",
    "\n",
    "    # border edit\n",
    "    x_ = np.zeros((x.size + window,))\n",
    "    x_[window // 2 : -window // 2] = x\n",
    "    x_ = x_ + np.random.normal(loc=0, scale=sys.float_info.epsilon, size=(x_.shape))\n",
    "\n",
    "    f, t, S = spectrogram(\n",
    "        x=x_,\n",
    "        fs=fs,\n",
    "        window=np.blackman(window),\n",
    "        nperseg=window,\n",
    "        noverlap=noverlap,\n",
    "        nfft=nfft,\n",
    "    )\n",
    "\n",
    "    S = S[(f > f_min) & (f <= f_max), :]\n",
    "    S = maxfilt(np.abs(S), size=(f_sub, 1))\n",
    "    S = S[::f_sub, :]\n",
    "    S = np.swapaxes(S, axis1=1, axis2=0)\n",
    "    S = np.log(S + sys.float_info.epsilon)\n",
    "\n",
    "    return S\n",
    "\n",
    "def convert_accel_to_spectrogram(accel_data, sampling_rate_Hz=32, nfft=512, window=320, noverlap=256):\n",
    "    spectrograms = []\n",
    "    for axis in range(1, accel_data.shape[1]):  # Skip time column\n",
    "        Sxx = cal_psd(accel_data[:, axis], fs=sampling_rate_Hz, nfft=nfft, window=window, noverlap=noverlap)\n",
    "        spectrograms.append(Sxx)\n",
    "    spectrograms = np.stack(spectrograms, axis=-1)\n",
    "    return spectrograms\n",
    "\n",
    "def pad_or_truncate(data, desired_length, pad_value: float = -1.0):\n",
    "    current_length = data.shape[0]\n",
    "    if current_length < desired_length:\n",
    "        padding = desired_length - current_length\n",
    "        pad_width = ((0, padding), (0, 0))\n",
    "        data = np.pad(data, pad_width, mode='constant', constant_values=pad_value)\n",
    "    else:\n",
    "        data = data[:desired_length, :]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_set(data_set: pds.DataSetObject, ids_to_exclude: List[str], ACTIVITY_KERNEL_WIDTH):\n",
    "    data = {}\n",
    "    for id in data_set.ids:\n",
    "        if id in ids_to_exclude:\n",
    "            continue\n",
    "        print(f\"Processing {id}\")\n",
    "        data[id] = process_data(data_set, id, ACTIVITY_KERNEL_WIDTH)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1066528\n",
      "Pre-mask:\n",
      "\tSleeps 767 \n",
      "\tWakes 179\n",
      "Post-mask:\n",
      "\tSleeps 618 \n",
      "\tWakes 132 \n",
      "\tWakes masked 41\n",
      "Processing 1360686\n",
      "Pre-mask:\n",
      "\tSleeps 831 \n",
      "\tWakes 93\n",
      "Post-mask:\n",
      "\tSleeps 823 \n",
      "\tWakes 88 \n",
      "\tWakes masked 0\n",
      "Processing 1449548\n",
      "Pre-mask:\n",
      "\tSleeps 848 \n",
      "\tWakes 104\n",
      "Post-mask:\n",
      "\tSleeps 744 \n",
      "\tWakes 92 \n",
      "\tWakes masked 7\n",
      "Processing 1455390\n",
      "Pre-mask:\n",
      "\tSleeps 871 \n",
      "\tWakes 84\n",
      "Post-mask:\n",
      "\tSleeps 870 \n",
      "\tWakes 80 \n",
      "\tWakes masked 0\n",
      "Processing 1818471\n",
      "Pre-mask:\n",
      "\tSleeps 948 \n",
      "\tWakes 10\n",
      "Post-mask:\n",
      "\tSleeps 948 \n",
      "\tWakes 10 \n",
      "\tWakes masked 0\n",
      "Processing 2598705\n",
      "Pre-mask:\n",
      "\tSleeps 934 \n",
      "\tWakes 20\n",
      "Post-mask:\n",
      "\tSleeps 740 \n",
      "\tWakes 14 \n",
      "\tWakes masked 6\n",
      "Processing 2638030\n",
      "Pre-mask:\n",
      "\tSleeps 825 \n",
      "\tWakes 123\n",
      "Post-mask:\n",
      "\tSleeps 825 \n",
      "\tWakes 123 \n",
      "\tWakes masked 0\n",
      "Processing 3997827\n",
      "Pre-mask:\n",
      "\tSleeps 933 \n",
      "\tWakes 25\n",
      "Post-mask:\n",
      "\tSleeps 929 \n",
      "\tWakes 25 \n",
      "\tWakes masked 0\n",
      "Processing 4018081\n",
      "Pre-mask:\n",
      "\tSleeps 419 \n",
      "\tWakes 79\n",
      "Post-mask:\n",
      "\tSleeps 419 \n",
      "\tWakes 65 \n",
      "\tWakes masked 8\n",
      "Processing 4314139\n",
      "Pre-mask:\n",
      "\tSleeps 857 \n",
      "\tWakes 104\n",
      "Post-mask:\n",
      "\tSleeps 857 \n",
      "\tWakes 99 \n",
      "\tWakes masked 0\n",
      "Processing 4426783\n",
      "Pre-mask:\n",
      "\tSleeps 909 \n",
      "\tWakes 69\n",
      "Post-mask:\n",
      "\tSleeps 904 \n",
      "\tWakes 64 \n",
      "\tWakes masked 0\n",
      "Processing 46343\n",
      "Pre-mask:\n",
      "\tSleeps 469 \n",
      "\tWakes 84\n",
      "Post-mask:\n",
      "\tSleeps 469 \n",
      "\tWakes 79 \n",
      "\tWakes masked 0\n",
      "Processing 5498603\n",
      "Pre-mask:\n",
      "\tSleeps 637 \n",
      "\tWakes 107\n",
      "Post-mask:\n",
      "\tSleeps 635 \n",
      "\tWakes 104 \n",
      "\tWakes masked 3\n",
      "Processing 5797046\n",
      "Pre-mask:\n",
      "\tSleeps 859 \n",
      "\tWakes 79\n",
      "Post-mask:\n",
      "\tSleeps 854 \n",
      "\tWakes 79 \n",
      "\tWakes masked 0\n",
      "Processing 6220552\n",
      "Pre-mask:\n",
      "\tSleeps 902 \n",
      "\tWakes 52\n",
      "Post-mask:\n",
      "\tSleeps 897 \n",
      "\tWakes 52 \n",
      "\tWakes masked 0\n",
      "Processing 781756\n",
      "Pre-mask:\n",
      "\tSleeps 897 \n",
      "\tWakes 82\n",
      "Post-mask:\n",
      "\tSleeps 888 \n",
      "\tWakes 77 \n",
      "\tWakes masked 0\n",
      "Processing 8000685\n",
      "Pre-mask:\n",
      "\tSleeps 924 \n",
      "\tWakes 33\n",
      "Post-mask:\n",
      "\tSleeps 891 \n",
      "\tWakes 31 \n",
      "\tWakes masked 0\n",
      "Processing 8173033\n",
      "Pre-mask:\n",
      "\tSleeps 926 \n",
      "\tWakes 29\n",
      "Post-mask:\n",
      "\tSleeps 922 \n",
      "\tWakes 29 \n",
      "\tWakes masked 0\n",
      "Processing 844359\n",
      "Pre-mask:\n",
      "\tSleeps 804 \n",
      "\tWakes 93\n",
      "Post-mask:\n",
      "\tSleeps 804 \n",
      "\tWakes 91 \n",
      "\tWakes masked 2\n",
      "Processing 8530312\n",
      "Pre-mask:\n",
      "\tSleeps 869 \n",
      "\tWakes 78\n",
      "Post-mask:\n",
      "\tSleeps 786 \n",
      "\tWakes 75 \n",
      "\tWakes masked 2\n",
      "Processing 8686948\n",
      "Pre-mask:\n",
      "\tSleeps 906 \n",
      "\tWakes 49\n",
      "Post-mask:\n",
      "\tSleeps 901 \n",
      "\tWakes 49 \n",
      "\tWakes masked 0\n",
      "Processing 8692923\n",
      "Pre-mask:\n",
      "\tSleeps 825 \n",
      "\tWakes 110\n",
      "Post-mask:\n",
      "\tSleeps 820 \n",
      "\tWakes 110 \n",
      "\tWakes masked 0\n",
      "Processing 9106476\n",
      "Pre-mask:\n",
      "\tSleeps 873 \n",
      "\tWakes 87\n",
      "Post-mask:\n",
      "\tSleeps 868 \n",
      "\tWakes 85 \n",
      "\tWakes masked 0\n",
      "Processing 9618981\n",
      "Pre-mask:\n",
      "\tSleeps 850 \n",
      "\tWakes 93\n",
      "Post-mask:\n",
      "\tSleeps 845 \n",
      "\tWakes 88 \n",
      "\tWakes masked 0\n",
      "Processing 1066528\n",
      "Pre-mask:\n",
      "\tSleeps 767 \n",
      "\tWakes 184\n",
      "Post-mask:\n",
      "\tSleeps 618 \n",
      "\tWakes 133 \n",
      "\tWakes masked 41\n",
      "Processing 1360686\n",
      "Pre-mask:\n",
      "\tSleeps 831 \n",
      "\tWakes 93\n",
      "Post-mask:\n",
      "\tSleeps 824 \n",
      "\tWakes 88 \n",
      "\tWakes masked 0\n",
      "Processing 1449548\n",
      "Pre-mask:\n",
      "\tSleeps 848 \n",
      "\tWakes 105\n",
      "Post-mask:\n",
      "\tSleeps 744 \n",
      "\tWakes 93 \n",
      "\tWakes masked 7\n",
      "Processing 1455390\n",
      "Pre-mask:\n",
      "\tSleeps 871 \n",
      "\tWakes 84\n",
      "Post-mask:\n",
      "\tSleeps 870 \n",
      "\tWakes 81 \n",
      "\tWakes masked 0\n",
      "Processing 1818471\n",
      "Pre-mask:\n",
      "\tSleeps 948 \n",
      "\tWakes 10\n",
      "Post-mask:\n",
      "\tSleeps 948 \n",
      "\tWakes 10 \n",
      "\tWakes masked 0\n",
      "Processing 2598705\n",
      "Pre-mask:\n",
      "\tSleeps 934 \n",
      "\tWakes 20\n",
      "Post-mask:\n",
      "\tSleeps 741 \n",
      "\tWakes 14 \n",
      "\tWakes masked 6\n",
      "Processing 2638030\n",
      "Pre-mask:\n",
      "\tSleeps 825 \n",
      "\tWakes 123\n",
      "Post-mask:\n",
      "\tSleeps 825 \n",
      "\tWakes 123 \n",
      "\tWakes masked 0\n",
      "Processing 3997827\n",
      "Pre-mask:\n",
      "\tSleeps 933 \n",
      "\tWakes 25\n",
      "Post-mask:\n",
      "\tSleeps 930 \n",
      "\tWakes 25 \n",
      "\tWakes masked 0\n",
      "Processing 4018081\n",
      "Pre-mask:\n",
      "\tSleeps 419 \n",
      "\tWakes 90\n",
      "Post-mask:\n",
      "\tSleeps 419 \n",
      "\tWakes 72 \n",
      "\tWakes masked 8\n",
      "Processing 4314139\n",
      "Pre-mask:\n",
      "\tSleeps 857 \n",
      "\tWakes 104\n",
      "Post-mask:\n",
      "\tSleeps 857 \n",
      "\tWakes 100 \n",
      "\tWakes masked 0\n",
      "Processing 4426783\n",
      "Pre-mask:\n",
      "\tSleeps 910 \n",
      "\tWakes 69\n",
      "Post-mask:\n",
      "\tSleeps 905 \n",
      "\tWakes 64 \n",
      "\tWakes masked 0\n",
      "Processing 46343\n",
      "Pre-mask:\n",
      "\tSleeps 469 \n",
      "\tWakes 85\n",
      "Post-mask:\n",
      "\tSleeps 469 \n",
      "\tWakes 80 \n",
      "\tWakes masked 0\n",
      "Processing 5498603\n",
      "Pre-mask:\n",
      "\tSleeps 637 \n",
      "\tWakes 107\n",
      "Post-mask:\n",
      "\tSleeps 636 \n",
      "\tWakes 104 \n",
      "\tWakes masked 3\n",
      "Processing 5797046\n",
      "Pre-mask:\n",
      "\tSleeps 860 \n",
      "\tWakes 79\n",
      "Post-mask:\n",
      "\tSleeps 855 \n",
      "\tWakes 79 \n",
      "\tWakes masked 0\n",
      "Processing 6220552\n",
      "Pre-mask:\n",
      "\tSleeps 902 \n",
      "\tWakes 53\n",
      "Post-mask:\n",
      "\tSleeps 898 \n",
      "\tWakes 52 \n",
      "\tWakes masked 0\n",
      "Processing 781756\n",
      "Pre-mask:\n",
      "\tSleeps 898 \n",
      "\tWakes 82\n",
      "Post-mask:\n",
      "\tSleeps 889 \n",
      "\tWakes 77 \n",
      "\tWakes masked 0\n",
      "Processing 8000685\n",
      "Pre-mask:\n",
      "\tSleeps 924 \n",
      "\tWakes 33\n",
      "Post-mask:\n",
      "\tSleeps 892 \n",
      "\tWakes 31 \n",
      "\tWakes masked 0\n",
      "Processing 8173033\n",
      "Pre-mask:\n",
      "\tSleeps 926 \n",
      "\tWakes 29\n",
      "Post-mask:\n",
      "\tSleeps 923 \n",
      "\tWakes 29 \n",
      "\tWakes masked 0\n",
      "Processing 844359\n",
      "Pre-mask:\n",
      "\tSleeps 804 \n",
      "\tWakes 93\n",
      "Post-mask:\n",
      "\tSleeps 804 \n",
      "\tWakes 91 \n",
      "\tWakes masked 2\n",
      "Processing 8530312\n",
      "Pre-mask:\n",
      "\tSleeps 869 \n",
      "\tWakes 78\n",
      "Post-mask:\n",
      "\tSleeps 787 \n",
      "\tWakes 75 \n",
      "\tWakes masked 2\n",
      "Processing 8686948\n",
      "Pre-mask:\n",
      "\tSleeps 906 \n",
      "\tWakes 49\n",
      "Post-mask:\n",
      "\tSleeps 902 \n",
      "\tWakes 49 \n",
      "\tWakes masked 0\n",
      "Processing 8692923\n",
      "Pre-mask:\n",
      "\tSleeps 826 \n",
      "\tWakes 110\n",
      "Post-mask:\n",
      "\tSleeps 821 \n",
      "\tWakes 110 \n",
      "\tWakes masked 0\n",
      "Processing 9106476\n",
      "Pre-mask:\n",
      "\tSleeps 874 \n",
      "\tWakes 87\n",
      "Post-mask:\n",
      "\tSleeps 869 \n",
      "\tWakes 85 \n",
      "\tWakes masked 0\n",
      "Processing 9618981\n",
      "Pre-mask:\n",
      "\tSleeps 850 \n",
      "\tWakes 93\n",
      "Post-mask:\n",
      "\tSleeps 845 \n",
      "\tWakes 88 \n",
      "\tWakes masked 0\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data_walch = process_data_set(walch, subjects_to_exclude_walch, ACTIVITY_KERNEL_WIDTH)\n",
    "preprocessed_data_hybrid = process_data_set(hybrid, subjects_to_exclude_hybrid, ACTIVITY_KERNEL_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to /Users/eric/Engineering/Work/sleepers_analysis/notebooks/pre_processed_data/walch/walch_preprocessed_data.npy...\n",
      "Saving to /Users/eric/Engineering/Work/sleepers_analysis/notebooks/pre_processed_data/hybrid/hybrid_preprocessed_data.npy...\n"
     ]
    }
   ],
   "source": [
    "# Prepare a bundle to save\n",
    "save_preprocessing_to = walch_path.joinpath(\"walch_preprocessed_data.npy\")\n",
    "print(f\"Saving to {save_preprocessing_to}...\")\n",
    "\n",
    "with open(save_preprocessing_to, 'wb') as f:\n",
    "    np.save(f, preprocessed_data_walch)\n",
    "\n",
    "save_preprocessing_to = hybrid_path.joinpath(\"hybrid_preprocessed_data.npy\")\n",
    "print(f\"Saving to {save_preprocessing_to}...\")\n",
    "with open(save_preprocessing_to, 'wb') as f:\n",
    "    np.save(f, preprocessed_data_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pisces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
