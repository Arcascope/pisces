{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Pisces baseline by loading data, making triplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from analyses.NHRC.nhrc_utils.analysis import DEFAULT_EVALUATION_DIR, SCENARIOS, STATIONARY_LOWER, HYBRID_LOWER\n",
    "import matplotlib.pyplot as plt\n",
    "from analyses.NHRC.nhrc_utils.analysis import ACCURACY_COLUMN, AUROC_COLUMN, MODEL_COLUMN, SCENARIO_COLUMN, SLEEP_ACCURACY_COLUMN, WASA_COLUMN\n",
    "from analyses.NHRC.nhrc_utils.plotting import tri_plot_metrics\n",
    "from analyses.NHRC.nhrc_utils.model_definitions import EXTRA_LAYERS_NAME, EXTRA_LOWER, LR_LOWER, NAIVE_LOWER\n",
    "from collections import defaultdict\n",
    "from analyses.NHRC.nhrc_utils.analysis import compute_evaluations_df\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Set this before importing TensorFlow\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from analyses.NHRC.nhrc_utils.analysis import DF_COLUMNS, WASA_SLEEP_ACCURACY, auroc_balaccuracy_wasa\n",
    "\n",
    "acc_hz_string = \"dyn\"\n",
    "WASA_SLEEP_PERCENT = 93\n",
    "STATIONARY_SET_NAME = \"Stationary Data\"\n",
    "HYBRID_SET_NAME = \"Hybrid Data\"\n",
    "SECOND_LINE = f\"Sleep Accuracy ≈ {WASA_SLEEP_PERCENT}%\"\n",
    "SECOND_TITLE_LINE = f\"Comparison of Stationary and Hybrid Data Metrics, {SECOND_LINE}\"\n",
    "TRIPLOT_DPI = 300\n",
    "\n",
    "scenarios = SCENARIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from analyses.NHRC.nhrc_utils.analysis import prepare_data\n",
    "\n",
    "sets_prepro_data = defaultdict(dict)\n",
    "\n",
    "\n",
    "for set_name in scenarios:\n",
    "    print(\"Loading\", set_name)\n",
    "    sets_prepro_data[set_name] = np.load(f'./pre_processed_data/{set_name}/{set_name}_preprocessed_data_{acc_hz_string}.npy', allow_pickle=True).item()\n",
    "\n",
    "stationary_data_bundle = prepare_data(sets_prepro_data['stationary'])\n",
    "hybrid_data_bundle = prepare_data(sets_prepro_data['hybrid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# rev_sets = reverse_dicts(rev_sets_prepro)\n",
    "walch_keys = list(sets_prepro_data['stationary'].keys())\n",
    "\n",
    "cnn_predictors = [\n",
    "    tf.keras.models.load_model(f\"/Users/eric/Engineering/Work/pisces/analyses/NHRC/evaluations/models/finetuning_{i}.keras\")\n",
    "    for i in walch_keys \n",
    "]\n",
    "\n",
    "lr_predictors = [\n",
    "    tf.keras.models.load_model(f\"/Users/eric/Engineering/Work/pisces/analyses/NHRC/evaluations/models/lr_{i}.keras\")\n",
    "    for i in walch_keys \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "evaluations_df = compute_evaluations_df(\n",
    "    walch_keys,\n",
    "    stationary_data_bundle,\n",
    "    hybrid_data_bundle,\n",
    "    lr_predictors,\n",
    "    cnn_predictors\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "cnn_evaluations_df = evaluations_df[evaluations_df[MODEL_COLUMN] == EXTRA_LOWER]\n",
    "cnn_evaluations_df = cnn_evaluations_df[cnn_evaluations_df[SLEEP_ACCURACY_COLUMN] == WASA_SLEEP_PERCENT]\n",
    "cnn_stationary = cnn_evaluations_df[cnn_evaluations_df[SCENARIO_COLUMN] == STATIONARY_LOWER]\n",
    "cnn_hybrid = cnn_evaluations_df[cnn_evaluations_df[SCENARIO_COLUMN] == HYBRID_LOWER]\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_ylim(0, 20)\n",
    "\n",
    "tri_plot_metrics(evaluations_df=cnn_stationary, axs=axs[0], axs_set_name=STATIONARY_SET_NAME,\n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "tri_plot_metrics(cnn_hybrid, axs=axs[1], axs_set_name=HYBRID_SET_NAME,\n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Mads Olsen's UNet + Arcascope {EXTRA_LAYERS_NAME} CNN\\n{SECOND_TITLE_LINE}\\nPISCES {acc_hz_string} Hz\", fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(DEFAULT_EVALUATION_DIR.joinpath(f\"{EXTRA_LOWER}_triplot_{WASA_SLEEP_PERCENT}_{acc_hz_string}.png\"), dpi=TRIPLOT_DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_hz_string = \"50\"\n",
    "sets_prepro_data = defaultdict(dict)\n",
    "\n",
    "\n",
    "for set_name in scenarios:\n",
    "    print(\"Loading\", set_name)\n",
    "    sets_prepro_data[set_name] = np.load(f'./pre_processed_data/{set_name}/{set_name}_preprocessed_data_{acc_hz_string}.npy', allow_pickle=True).item()\n",
    "\n",
    "stationary_data_bundle_50 = prepare_data(sets_prepro_data['stationary'])\n",
    "hybrid_data_bundle_50 = prepare_data(sets_prepro_data['hybrid'])\n",
    "\n",
    "evaluations_df_50 = compute_evaluations_df(\n",
    "    walch_keys,\n",
    "    stationary_data_bundle_50,\n",
    "    hybrid_data_bundle_50,\n",
    "    lr_predictors,\n",
    "    cnn_predictors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "cnn_evaluations_df = evaluations_df_50[evaluations_df_50[MODEL_COLUMN] == EXTRA_LOWER]\n",
    "cnn_evaluations_df = cnn_evaluations_df[cnn_evaluations_df[SLEEP_ACCURACY_COLUMN] == WASA_SLEEP_PERCENT]\n",
    "cnn_stationary = cnn_evaluations_df[cnn_evaluations_df[SCENARIO_COLUMN] == STATIONARY_LOWER]\n",
    "cnn_hybrid = cnn_evaluations_df[cnn_evaluations_df[SCENARIO_COLUMN] == HYBRID_LOWER]\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_ylim(0, 20)\n",
    "\n",
    "tri_plot_metrics(evaluations_df=cnn_stationary, axs=axs[0], axs_set_name=STATIONARY_SET_NAME,\n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "tri_plot_metrics(cnn_hybrid, axs=axs[1], axs_set_name=HYBRID_SET_NAME,\n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Mads Olsen's UNet + Arcascope {EXTRA_LAYERS_NAME} CNN\\n{SECOND_TITLE_LINE}\\nPISCES {acc_hz_string} Hz\", fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(DEFAULT_EVALUATION_DIR.joinpath(f\"{EXTRA_LOWER}_triplot_{WASA_SLEEP_PERCENT}.png\"), dpi=TRIPLOT_DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from analyses.NHRC.nhrc_utils.analysis import SCENARIOS\n",
    "\n",
    "\n",
    "specgram_folder = Path('/Users/eric/Engineering/Work/pisces/data_sets/specgrams')\n",
    "\n",
    "specgram_data = defaultdict(dict)\n",
    "\n",
    "scenarios = SCENARIOS\n",
    "print(scenarios)\n",
    "\n",
    "for file in specgram_folder.joinpath('NSR').glob('*.npy'):\n",
    "    scenario, subject_id = file.stem.split('_')[:2]\n",
    "    specgram_data[scenario][subject_id] = np.squeeze(np.load(file, allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specgram_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = sorted(list(specgram_data['stationary'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsr_stationary = np.array([specgram_data['stationary'][subject_id] for subject_id in keys])\n",
    "nsr_hybrid = np.array([specgram_data['hybrid'][subject_id] for subject_id in keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "datas = [\n",
    "    [stationary_data_bundle.spectrogram[0], hybrid_data_bundle.spectrogram[0]],\n",
    "    [nsr_stationary[0], nsr_hybrid[0]]\n",
    "]\n",
    "\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        array = np.squeeze(datas[row][col])\n",
    "        ax[row][col].imshow(array.T, aspect='auto', vmin=-15, vmax=20)\n",
    "        ax[0][col].set_title(['Stationary', 'Hybrid'][col])\n",
    "    ax[row][0].set_ylabel(['Pisces', 'NSR'][row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed NSR exports into Pisces' MO evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move NSR exports into bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_keys = 0\n",
    "rev_sets_prepro = sets_prepro_data\n",
    "for key in rev_sets_prepro.keys():\n",
    "    pisces_prepro = rev_sets_prepro[key]\n",
    "    nsr_prepro = specgram_data.get(key)\n",
    "\n",
    "    if nsr_prepro is None:\n",
    "        print(\"No NSR data for\", key)\n",
    "        continue\n",
    "\n",
    "    print(\"Processing\", key)\n",
    "\n",
    "    for iden in pisces_prepro.keys():\n",
    "        diff = rev_sets_prepro[key][iden]['spectrogram'] - nsr_prepro[iden]\n",
    "        # print(f\"Diff: [{diff.min()}, {diff.max()}], μ: {diff.mean()}\")\n",
    "        if iden not in nsr_prepro.keys():\n",
    "            missed_keys += 1\n",
    "            print(\"Missing\", iden, \"from NSR\", key)\n",
    "            continue\n",
    "        rev_sets_prepro[key][iden]['spectrogram.backup'] = rev_sets_prepro[key][iden]['spectrogram']\n",
    "        rev_sets_prepro[key][iden]['spectrogram'] = nsr_prepro[iden]\n",
    "diff = rev_sets_prepro['stationary'][iden]['spectrogram'] - rev_sets_prepro['hybrid'][iden]['spectrogram']\n",
    "print(f\"{iden} Diff: [{diff.min()}, {diff.max()}], μ: {diff.mean()}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# rev_sets = reverse_dicts(rev_sets_prepro)\n",
    "rev_sets = sets_prepro_data\n",
    "\n",
    "hybrid_preprocessed_data = rev_sets['hybrid']\n",
    "walch_preprocessed_data = rev_sets['stationary']\n",
    "hybrid_data_bundle_NSR = prepare_data(hybrid_preprocessed_data)\n",
    "stationary_data_bundle_NSR = prepare_data(walch_preprocessed_data)\n",
    "\n",
    "evaluations_df_NSR = compute_evaluations_df(\n",
    "    walch_keys,\n",
    "    stationary_data_bundle_NSR,\n",
    "    hybrid_data_bundle_NSR,\n",
    "    lr_predictors,\n",
    "    cnn_predictors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pisces.data_sets import DataSetObject\n",
    "\n",
    "data_location = Path('/Users/eric/Engineering/Work/pisces/data_sets')\n",
    "\n",
    "found_sets = DataSetObject.find_data_sets(data_location)\n",
    "stationary_base = found_sets['walch_et_al']\n",
    "hybrid_base = found_sets['hybrid_motion']\n",
    "\n",
    "stationary_base.parse_data_sets()\n",
    "hybrid_base.parse_data_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_id = stationary_base.ids[0]\n",
    "\n",
    "s0_acc = stationary_base.get_feature_data('accelerometer', s0_id)\n",
    "h0_acc = hybrid_base.get_feature_data('accelerometer', s0_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h0_acc[:, 0], h0_acc[:, 1:], 'o')\n",
    "plt.plot(s0_acc[:, 0], s0_acc[:, 1:], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "ax[0].imshow(stationary_data_bundle.spectrogram[0].numpy().T, aspect='auto')\n",
    "ax[1].imshow(hybrid_data_bundle.spectrogram[0].numpy().T, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(stationary_data_bundle.mo_predictions[0].numpy().T - hybrid_data_bundle.mo_predictions[0].numpy().T).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's the spectrograms\n",
    "Specifically, the accelerometer resampling between NSR and pisces seems to be introducing differences! The Pisces-era eval loop below will discover the same outlier behavior as we saw in NSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "cnn_evaluations_df = evaluations_df_NSR[evaluations_df_NSR[MODEL_COLUMN] == EXTRA_LOWER]\n",
    "cnn_evaluations_df = cnn_evaluations_df[cnn_evaluations_df[SLEEP_ACCURACY_COLUMN] == WASA_SLEEP_PERCENT]\n",
    "cnn_stationary = cnn_evaluations_df[cnn_evaluations_df[SCENARIO_COLUMN] == STATIONARY_LOWER]\n",
    "cnn_hybrid = cnn_evaluations_df[cnn_evaluations_df[SCENARIO_COLUMN] == HYBRID_LOWER]\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_ylim(0, 20)\n",
    "\n",
    "tri_plot_metrics(evaluations_df=cnn_stationary, axs=axs[0], axs_set_name=STATIONARY_SET_NAME,\n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "tri_plot_metrics(cnn_hybrid, axs=axs[1], axs_set_name=HYBRID_SET_NAME,\n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Mads Olsen's UNet + Arcascope {EXTRA_LAYERS_NAME} CNN\\n{SECOND_TITLE_LINE}\\nNavySleepResearch\", fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(DEFAULT_EVALUATION_DIR.joinpath(f\"{EXTRA_LOWER}_triplot_{WASA_SLEEP_PERCENT}.png\"), dpi=TRIPLOT_DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "naive_evaluations_df = evaluations_df_NSR[evaluations_df_NSR[MODEL_COLUMN] == NAIVE_LOWER]\n",
    "naive_evaluations_df = naive_evaluations_df[naive_evaluations_df[SLEEP_ACCURACY_COLUMN] == WASA_SLEEP_PERCENT]\n",
    "naive_stationary = naive_evaluations_df[naive_evaluations_df[SCENARIO_COLUMN] == STATIONARY_LOWER]\n",
    "naive_hybrid = naive_evaluations_df[naive_evaluations_df[SCENARIO_COLUMN] == HYBRID_LOWER]\n",
    "\n",
    "tri_plot_metrics(naive_stationary, axs=axs[0], axs_set_name=STATIONARY_SET_NAME, \n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "tri_plot_metrics(naive_hybrid, axs=axs[1], axs_set_name=HYBRID_SET_NAME, \n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "for ax in axs.flatten():\n",
    "    ax.set_ylim(0, 20)\n",
    "\n",
    "fig.suptitle(f\"Mads Olsen's UNet => Naive 1 - Pr(W)\\n{SECOND_TITLE_LINE}\", fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(DEFAULT_EVALUATION_DIR.joinpath(f\"{NAIVE_LOWER}_triplot_{WASA_SLEEP_PERCENT}.png\"), dpi=TRIPLOT_DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tri plot for logistic regression CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "lr_evaluations_df = evaluations_df[evaluations_df[MODEL_COLUMN] == LR_LOWER]\n",
    "lr_evaluations_df = lr_evaluations_df[lr_evaluations_df[SLEEP_ACCURACY_COLUMN] == WASA_SLEEP_PERCENT]\n",
    "lr_stationary = lr_evaluations_df[lr_evaluations_df[SCENARIO_COLUMN] == STATIONARY_LOWER]\n",
    "lr_hybrid = lr_evaluations_df[lr_evaluations_df[SCENARIO_COLUMN] == HYBRID_LOWER]\n",
    "\n",
    "tri_plot_metrics(lr_stationary, axs=axs[0], axs_set_name=STATIONARY_SET_NAME,\n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "tri_plot_metrics(lr_hybrid, axs=axs[1], axs_set_name=HYBRID_SET_NAME,\n",
    "                 wasa_column=WASA_COLUMN, accuracy_column=ACCURACY_COLUMN, auroc_column=AUROC_COLUMN)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_ylim(0, 20)\n",
    "\n",
    "fig.suptitle(f\"Logistic Regression in TF\\n{SECOND_TITLE_LINE}\", fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(DEFAULT_EVALUATION_DIR.joinpath(f\"{LR_LOWER}_triplot_{WASA_SLEEP_PERCENT}.png\"), dpi=TRIPLOT_DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pisces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
